{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389e00b4",
   "metadata": {},
   "source": [
    "kig på data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68dc647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc6fda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/diagnosis.csv\"\n",
    "diagnosis_df = pd.read_csv(path, sep=';')\n",
    "\n",
    "df = pd.read_parquet('data/CaseRigshospitalet_optimized.parquet')\n",
    "\n",
    " # Remove all Akut contacts\n",
    "df = df[df['Indlæggelsesmåde'] != 'Akut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f49deeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Indlæggelsesmåde'] != 'Akut']\n",
    "\n",
    "df = df[df[\"Patient ID\"].astype(str).str.strip().ne(\"\")]\n",
    "\n",
    "df = df[df[\"Aktionsdiagnosekode\"].astype(str).str.strip().ne(\"\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29e1bae",
   "metadata": {},
   "source": [
    "### Diagnosis tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bedd6a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "code = \"Aktionsdiagnosekode\"\n",
    "text = \"Aktionsdiagnosetekst\"\n",
    "token_dict = {}\n",
    "\n",
    "for idx, row in diagnosis_df.iterrows():\n",
    "    code_val = row[\"Aktionsdiagnosekode\"]\n",
    "    text_val = row[\"Aktionsdiagnosetekst\"]\n",
    "\n",
    "    text1 = str(code_val) if pd.notnull(code_val) else \"\"\n",
    "    text2 = str(text_val) if pd.notnull(text_val) else \"\"\n",
    "    combined_text = text1 + \" \" + text2\n",
    "    token_dict[code_val] = combined_text\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9a05b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jacob\\AppData\\Local\\Temp\\ipykernel_12272\\820759188.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  unique_diag_lists = df.groupby(\"Patient ID\")[\"Aktionsdiagnosekode\"].unique()\n"
     ]
    }
   ],
   "source": [
    "unique_diag_lists = df.groupby(\"Patient ID\")[\"Aktionsdiagnosekode\"].unique()\n",
    "\n",
    "patient_records = {}\n",
    "\n",
    "for patient_id, codes in unique_diag_lists.items():\n",
    "    diagnoses = [token_dict[str(code)] for code in codes if str(code) in token_dict]\n",
    "    patient_records[patient_id] = {\n",
    "        \"diagnoses\": diagnoses\n",
    "        # you can add 'medications' and 'context' here if you have them\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cde19a",
   "metadata": {},
   "source": [
    "### Demographics token\n",
    "\n",
    "we need age_group, gender, civil_tilstand and kommune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3d53da27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make age groups\n",
    "\n",
    "age_bins = [0, 5, 18, 25, 35, 45, 55, 65, 75, 80, 85, 90, 99,  float(\"inf\")]\n",
    "age_labels = [f\"Age_Group_{str(i).zfill(2)}\" for i in range(13)]\n",
    "df[\"Age_Group\"] = pd.cut(\n",
    "    df[\"Patient alder på kontaktstart tidspunkt\"],\n",
    "    bins=age_bins,\n",
    "    labels=age_labels,\n",
    "    right=True,\n",
    "    include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59e2cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df[\"Age_Group\"] = pd.cut(\n",
    "    df[\"Patient alder på kontaktstart tidspunkt\"],\n",
    "    bins=age_bins,\n",
    "    labels=age_labels,\n",
    "    include_lowest=True,\n",
    "    right=True\n",
    ")\n",
    "\n",
    "# Clean up relevant columns\n",
    "df[\"Patient køn\"] = df[\"Patient køn\"].astype(str).str.strip()\n",
    "df[\"Patient civilstand\"] = df[\"Patient civilstand\"].astype(str).str.strip()\n",
    "df[\"Patient kommune\"] = df[\"Patient kommune\"].astype(str).str.strip()\n",
    "df[\"Age_Group\"] = df[\"Age_Group\"].astype(str).str.strip()\n",
    "\n",
    "# Build demographic tokens (context) per row\n",
    "def demographic_tokens(row):\n",
    "    tokens = []\n",
    "    if row[\"Patient køn\"]:\n",
    "        tokens.append(f\"Sex_{row['Patient køn']}\")\n",
    "    if row[\"Patient civilstand\"]:\n",
    "        tokens.append(row[\"Patient civilstand\"])\n",
    "    if row[\"Patient kommune\"]:\n",
    "        tokens.append(f\"Kommune_{row['Patient kommune']}\")\n",
    "    if row[\"Age_Group\"]:\n",
    "        tokens.append(row[\"Age_Group\"])\n",
    "    return tokens\n",
    "\n",
    "df[\"context\"] = df.apply(demographic_tokens, axis=1)\n",
    "\n",
    "# Remove rows with no context tokens\n",
    "df = df[df[\"context\"].map(lambda x: len(x) > 0)]\n",
    "\n",
    "# Group by patient and take the first valid context list per patient\n",
    "context_dict = (\n",
    "    df.groupby(\"Patient ID\")[\"context\"]\n",
    "    .first()\n",
    "    .to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d541f200",
   "metadata": {},
   "source": [
    "### Pyro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdc0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.nn import PyroSample\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "\n",
    "def model(w_diag, w_context, num_topics, vocab_diag_size, vocab_context_size):\n",
    "    num_records = len(w_diag)\n",
    "\n",
    "    alpha = 0.1 * torch.ones(num_topics)\n",
    "    beta_diag = 0.1 * torch.ones(vocab_diag_size)\n",
    "    beta_context = 0.1 * torch.ones(vocab_context_size)\n",
    "\n",
    "    # Topic-word distributions for diagnoses and context\n",
    "    phi_diag = pyro.sample(\"phi_diag\", dist.Dirichlet(beta_diag).expand([num_topics]).to_event(1))  # (T x V_diag)\n",
    "    phi_context = pyro.sample(\"phi_context\", dist.Dirichlet(beta_context).expand([num_topics]).to_event(1))  # (T x V_context)\n",
    "\n",
    "    for v in pyro.plate(\"records\", num_records):\n",
    "        # Topic mixture for this record\n",
    "        theta_v = pyro.sample(f\"theta_{v}\", dist.Dirichlet(alpha))\n",
    "\n",
    "        # Diagnoses\n",
    "        for n in pyro.plate(f\"diag_tokens_{v}\", len(w_diag[v])):\n",
    "            z = pyro.sample(f\"z_diag_{v}_{n}\", dist.Categorical(theta_v))\n",
    "            pyro.sample(f\"w_diag_{v}_{n}\", dist.Categorical(phi_diag[z]), obs=w_diag[v][n])\n",
    "\n",
    "        # Contextual tokens\n",
    "        for n in pyro.plate(f\"context_tokens_{v}\", len(w_context[v])):\n",
    "            z = pyro.sample(f\"z_context_{v}_{n}\", dist.Categorical(theta_v))\n",
    "            pyro.sample(f\"w_context_{v}_{n}\", dist.Categorical(phi_context[z]), obs=w_context[v][n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8b0ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from pyro.nn import PyroSample\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.infer.autoguide import AutoDelta\n",
    "\n",
    "def model(w_diag, w_context, time_spent, num_topics, vocab_diag_size, vocab_context_size):\n",
    "    num_records = len(w_diag)\n",
    "\n",
    "    alpha = 0.1 * torch.ones(num_topics)\n",
    "    beta_diag = 0.1 * torch.ones(vocab_diag_size)\n",
    "    beta_context = 0.1 * torch.ones(vocab_context_size)\n",
    "\n",
    "    # Per-topic word distributions\n",
    "    phi_diag = pyro.sample(\"phi_diag\", dist.Dirichlet(beta_diag).expand([num_topics]).to_event(1))\n",
    "    phi_context = pyro.sample(\"phi_context\", dist.Dirichlet(beta_context).expand([num_topics]).to_event(1))\n",
    "\n",
    "    # Regression parameters for hospital time\n",
    "    with pyro.plate(\"topic_coeffs\"):\n",
    "        beta = pyro.sample(\"beta\", dist.Normal(0., 1.).expand([num_topics]).to_event(1))\n",
    "    sigma = pyro.sample(\"sigma\", dist.HalfCauchy(1.0))\n",
    "\n",
    "    for v in pyro.plate(\"records\", num_records):\n",
    "        # Latent topic mixture for the record\n",
    "        theta_v = pyro.sample(f\"theta_{v}\", dist.Dirichlet(alpha))\n",
    "\n",
    "        for n in pyro.plate(f\"diag_tokens_{v}\", len(w_diag[v])):\n",
    "            z = pyro.sample(f\"z_diag_{v}_{n}\", dist.Categorical(theta_v))\n",
    "            pyro.sample(f\"w_diag_{v}_{n}\", dist.Categorical(phi_diag[z]), obs=w_diag[v][n])\n",
    "\n",
    "        for n in pyro.plate(f\"context_tokens_{v}\", len(w_context[v])):\n",
    "            z = pyro.sample(f\"z_context_{v}_{n}\", dist.Categorical(theta_v))\n",
    "            pyro.sample(f\"w_context_{v}_{n}\", dist.Categorical(phi_context[z]), obs=w_context[v][n])\n",
    "\n",
    "        # Time spent modeled as a linear regression on theta\n",
    "        mu = (theta_v * beta).sum()\n",
    "        pyro.sample(f\"time_spent_{v}\", dist.Normal(mu, sigma), obs=time_spent[v])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
